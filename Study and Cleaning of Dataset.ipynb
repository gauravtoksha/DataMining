{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim: Study and cleaning of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Dataset:\n",
    "The dataset contains the crawled articles from the internet from around 87 websites for the year 2017\n",
    "it has url of the page,Source of the website,crawl time , title of the news, summary and trimmed descriptions\n",
    "it has 4 .csv partitions which aggregates to over 1gb\n",
    "Since there is no character encoding on the dataset , each partition is first converted to excel files in UTF-8\n",
    "this results in reduction of filesize by the factor of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features:\n",
    "- **url**\t: it is the URL of the article from which the data is crawled\n",
    "- **source**\t:Name of the newspaper\n",
    "- **crawl_time**\t:Timestamp of crawling\n",
    "- **title**: Title of the news\n",
    "- **trimmed_description**\t: A trimmed description of the summary, sometimes this is bigger than the summar itself\n",
    "- **summary** : summary of the news, also our main focus is on this column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further study of the dataset is done while creating a crawler for the dataset, This approach gave me more insight to the following questions:\n",
    "- Is the dataset bias in some category? : No, the type of news for eg: sports,health,government are very much spreaded and the dataset is very well formed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Python?**: The choice of choosing the programming language is completely based on the general benefits of the language,we have R which is a very well made language especially used for Data Science, And we have Python which is used for almost everything and still has a reasonable opensource support for implementing Data Science models.<br>\n",
    "Python does more than R in other fields but it has its own trade off for that kindof accessibility<br>\n",
    "and Since this was an introductory course, choosing Python over R creates more opportunities and keep all other options open for me ie not only data science,Ofcourse R is a much better platform and it is essential to know both since every dataset has its own fabric, Using both of the tool in combination when appropriate will give you a much better result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data and loading necessary modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.loading necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# pandas for data manipulation\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "# nltk for nlp\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# list of stopwords like articles, preposition\n",
    "stop = set(stopwords.words('english'))\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from nltk.tag import StanfordNERTagger\n",
    "import datefinder,datetime\n",
    "st = StanfordNERTagger('C:\\\\Users\\windows\\\\Downloads\\\\Compressed\\\\stanford-ner-2018-02-27\\\\stanford-ner-2018-02-27\\\\classifiers\\\\english.all.3class.distsim.crf.ser.gz',\n",
    "\t\t\t\t\t   'C:\\\\Users\\\\windows\\\\Downloads\\\\Compressed\\\\stanford-ner-2018-02-27\\\\stanford-ner-2018-02-27\\\\stanford-ner.jar',\n",
    "\t\t\t\t\t   encoding='utf-8')\n",
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### loading the dataset:\n",
    "The dataset has been divided into 4 parts,document is focused only on the first 1Lac records of first part at the moment\n",
    "due to memory and cpu constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reading from a excel ,skipfooter defines how many rows you want to leave\n",
    "df=pd.read_excel(r'C:\\Users\\windows\\Desktop\\Bigdata dataset\\1.xlsx',skipfooter=350000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2=pd.read_excel(r'C:\\Users\\windows\\Desktop\\Bigdata dataset\\2.xlsx',skipfooter=400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df3=pd.read_excel(r'C:\\Users\\windows\\Desktop\\Bigdata dataset\\3.xlsx',skipfooter=279000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df4=pd.read_excel(r'C:\\Users\\windows\\Desktop\\Bigdata dataset\\4.xlsx',skipfooter=210000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the cities has been downloaded from the internet for retrieving and removal of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities=pd.read_excel(r'C:\\Users\\windows\\Desktop\\Bigdata dataset\\Cities.xls')\n",
    "cities.columns\n",
    "cities=cities.dropna()\n",
    "citylist=cities['Name of City'].values\n",
    "statelist=set(cities['State'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Appending all the above dataframes into\n",
    "# dfl=[]\n",
    "# dfl.append(df1)\n",
    "# dfl.append(df2)\n",
    "# dfl.append(df3)\n",
    "# dfl.append(df4)\n",
    "# df=pd.concat(dfl,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100281, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape ## here we have the size of the data we are going to work upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>crawl_time</th>\n",
       "      <th>title</th>\n",
       "      <th>trimmed_description</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.thehindu.com/news/national/New-Army...</td>\n",
       "      <td>The Hindu</td>\n",
       "      <td>2017-01-01T00:19:03Z</td>\n",
       "      <td>New Army, Air Force Chiefs assume charge</td>\n",
       "      <td>The Army and the Air Force got new chiefs on S...</td>\n",
       "      <td>The Army and the Air Force got new chiefs on S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.thehindu.com/news/national/kerala/K...</td>\n",
       "      <td>The Hindu</td>\n",
       "      <td>2017-01-01T00:19:03Z</td>\n",
       "      <td>KSRTC unions call for stir on Jan. 4</td>\n",
       "      <td>The Indian National Trade Union Congress (INTU...</td>\n",
       "      <td>Utility needs â‚¹174.5 crore to pay salary, two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.thehindu.com/news/cities/mumbai/Luc...</td>\n",
       "      <td>The Hindu</td>\n",
       "      <td>2017-01-01T00:19:03Z</td>\n",
       "      <td>Lucky escape for tourists in SGNP bus mishap</td>\n",
       "      <td>Mumbai: More than 30 people on board a bus ope...</td>\n",
       "      <td>Mumbai: More than 30 people on board a bus ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.thehindu.com/news/cities/Hyderabad/...</td>\n",
       "      <td>The Hindu</td>\n",
       "      <td>2017-01-01T00:19:03Z</td>\n",
       "      <td>2016: A successful year for Tollywood</td>\n",
       "      <td>The year just gone by will undoubtedly go down...</td>\n",
       "      <td>The year saw a diverse range of movies being r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.sify.com/news/china-to-ban-ivory-tr...</td>\n",
       "      <td>Sify</td>\n",
       "      <td>2017-01-01T00:19:04Z</td>\n",
       "      <td>China to ban ivory trade by end of 2017</td>\n",
       "      <td>php //if(function_exists('ismobile') &amp;&amp; !ismob...</td>\n",
       "      <td>Beijing: China will ban the processing and sal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url     source  \\\n",
       "0  http://www.thehindu.com/news/national/New-Army...  The Hindu   \n",
       "1  http://www.thehindu.com/news/national/kerala/K...  The Hindu   \n",
       "2  http://www.thehindu.com/news/cities/mumbai/Luc...  The Hindu   \n",
       "3  http://www.thehindu.com/news/cities/Hyderabad/...  The Hindu   \n",
       "4  http://www.sify.com/news/china-to-ban-ivory-tr...       Sify   \n",
       "\n",
       "             crawl_time                                         title  \\\n",
       "0  2017-01-01T00:19:03Z      New Army, Air Force Chiefs assume charge   \n",
       "1  2017-01-01T00:19:03Z          KSRTC unions call for stir on Jan. 4   \n",
       "2  2017-01-01T00:19:03Z  Lucky escape for tourists in SGNP bus mishap   \n",
       "3  2017-01-01T00:19:03Z         2016: A successful year for Tollywood   \n",
       "4  2017-01-01T00:19:04Z       China to ban ivory trade by end of 2017   \n",
       "\n",
       "                                 trimmed_description  \\\n",
       "0  The Army and the Air Force got new chiefs on S...   \n",
       "1  The Indian National Trade Union Congress (INTU...   \n",
       "2  Mumbai: More than 30 people on board a bus ope...   \n",
       "3  The year just gone by will undoubtedly go down...   \n",
       "4  php //if(function_exists('ismobile') && !ismob...   \n",
       "\n",
       "                                             summary  \n",
       "0  The Army and the Air Force got new chiefs on S...  \n",
       "1  Utility needs â‚¹174.5 crore to pay salary, two ...  \n",
       "2  Mumbai: More than 30 people on board a bus ope...  \n",
       "3  The year saw a diverse range of movies being r...  \n",
       "4  Beijing: China will ban the processing and sal...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() ## top 5 records to see how the data looks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title , trimmed_description and summary contains the title of the newspaper which will harm the analysis and hence it has removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1:Remove the names of newspapers from the title and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newspaper_df=df['source'] ##storing the source column which has the names of the newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newspaper_df=newspaper_df.drop_duplicates() ## removing duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsnamelist=newspaper_df.values ## dropping null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsnamelist ## this list contains the names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datatypes\n",
    "since the data is imported in Dataframes,python will try to assign datatypes on its own and this is where the confusion gets created, You will get \"expected buffer or string type\" when the dtypes are not consistent and hence for ease of operation,its better to specify the dtypes before and do the cleaning of null values before performing an transformation on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##specifying the dtypes of the columns\n",
    "df['url']=df['url'].astype(str)\n",
    "df['title']=df['title'].astype(str)\n",
    "df['trimmed_description']=df['trimmed_description'].astype(str)\n",
    "df['summary']=df['summary'].astype(str)\n",
    "df['source']=df['source'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100281, 6)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['title']=df['title'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['summary']=df['summary'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['title']=df['title'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['summary']=df['summary'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['trimmed_description']=df['trimmed_description'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['trimmed_description']=df['trimmed_description'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## change to string\n",
    "def toString(text):\n",
    "    text=str(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['title']=df['title'].apply(lambda x:toString(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['summary']=df['summary'].apply(lambda x:toString(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['trimmed_description']=df['trimmed_description'].apply(lambda x:toString(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['source']=df['source'].apply(lambda x:toString(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['crawl_time']=df['crawl_time'].apply(lambda x:toString(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.source!='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.title!='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.trimmed_description!='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.url!='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.summary!='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.source!='NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.title!='NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.trimmed_description!='NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.url!='NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.summary!='NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68557, 6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                    object\n",
       "source                 object\n",
       "crawl_time             object\n",
       "title                  object\n",
       "trimmed_description    object\n",
       "summary                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
