{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling the websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Crawl the URLs given in the dataset and look for categories in the websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the web crawler was pretty straightforward.<br>\n",
    "Python has really good opensource support for crawling the webpages online.<br>\n",
    "Packages used :<br>\n",
    "-  BeautifulSoup - An opensource solution to easily locate information in a html page given an html tag\n",
    "-  requests - this is required for requesting the webpage and to download it locally to perform information search\n",
    "-  pandas - dataset is imported to pandas dataframe which makes it easy to access the data columnwise\n",
    "-  openpyxl - for writing each output to an excel file\n",
    "-  datefinder - to properly parsed a given string into a datetime object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues encountered:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Inconsistent Web Page Practices:most of the websites doesnt include any support fot metadata, This makes crawling really difficult since there is no consistent practice to store the information on the web page,This is probably due to unprofessional/ unexperienced developers<br>\n",
    "- Slow Process:Crawling is really slow and tiring process if you dont have the sufficient resources for eg:Multiple Online Servers And since your machine has to constantly request for pages online this also creates congestion in the network\n",
    "- Network Dependent:if your network becomes unresponsive this will stop the process of crawling \n",
    "- repeated requests:if you request a server again and again within a short period of time, it is possible that your ip will get blacklisted and you wont be able to crawl again\n",
    "- Crawling support: most of the webpages on the internet has Robots.txt file which provides rules as to which content you are allowed to crawl and which are not.Some dont allow any crawling whatsoever\n",
    "- Constantly writing to file: crawling is not suitable for saving the records into ram,you have to keep writing to a file to make sure you dont lose any progress if an unexpected event happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of Total 87 Unique websites from the datasets, 62 websites are perfectly crawlable (some needs effort to look for information).the remaining 25 websites are either not crawlable or they dont give you the access to crawl,some dont have proper tags to look for information ,some dont even have the categories to look for,some has inconsistent web meta data structure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since every website has a different information structure it becomes unavoidable to write unique conditions to look for information at each websites which is a really tiring process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some websites have 'Category tags',some has 'tags' which gives only related topics.My initial approach is to look for Category tag first, if it is not there then look for related tags and if there are multiple tags select the first one. since this is not consistent in websites , it is possible to get the names of personalities instead of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import datefinder\n",
    "from openpyxl import Workbook\n",
    "import openpyxl\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=pd.read_excel(r'C:\\Users\\windows\\Desktop\\Bigdata dataset\\1.xlsx',usecols=[0],sep='/t',lineterminator='/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls=df1.url.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "book = openpyxl.load_workbook(r'C:\\Users\\windows\\Desktop\\Bigdata dataset\\book1.xlsx')\n",
    "sheet=book.get_sheet_by_name(\"Sheet1\")\n",
    "for pg in urls[sheet.max_row-1:]:\n",
    "    cls=\"\"\n",
    "    datetime=\"\"\n",
    "    try:\n",
    "        r=requests.get(pg)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print (e)\n",
    "        continue\n",
    "    r.encoding='utf-8'\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "    if \"thehindu.com\" in pg:\n",
    "        publishbox=soup.find('none')\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        data = soup.findAll('div',attrs={'class':'tag-button'})\n",
    "        if data is not None:\n",
    "            for div in data:\n",
    "                a=div.findAll('a')\n",
    "                for c in a:\n",
    "                    cls=c.text.strip()\n",
    "        if cls==\"\":\n",
    "            maincat=soup.find('a',attrs={'class':'tag-button section-button'})\n",
    "            if maincat is not None:\n",
    "                cls=maincat.text.strip()\n",
    "        \n",
    "    elif \"accommodationtimes.com\" in pg:\n",
    "        publishbox=soup.find('div',attrs={'id':'datemeta_1'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        cls='Real Estate'\n",
    "        \n",
    "    elif \"afaqs.com\" in pg:\n",
    "        publishbox=soup.find('div',attrs={'class':'repo_name'})\n",
    "        if publishbox is not None:\n",
    "            str=publishbox.text.strip()\n",
    "            str=str.split('|')\n",
    "            cls=str[1]\n",
    "            cls=cls.split(' ')[2].strip()\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        \n",
    "    elif \"betterphotography.in\" in pg:\n",
    "        publishbox=soup.find('time')\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        cls=\"photography\"\n",
    "        \n",
    "    elif \"bollywoodhungama.com\" in pg:\n",
    "        publishbox=soup.find('time')\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'class':'tag-links'})\n",
    "        if tags is not None:\n",
    "            tags=tags.text.strip()\n",
    "            cls=tags.split(',')[0].split(':')[1].strip()\n",
    "        \n",
    "    elif \"bollywoodhungama.com/movie\" in pg:\n",
    "        publishbox=soup.find('time')\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        cls='movie'\n",
    "        \n",
    "    elif \"breakingnews.ie\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'class':'date-time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'class':'keywords'})\n",
    "        if tags is not None:\n",
    "            tags=tags.text.strip()\n",
    "            cls=tags.split(',')[0].split(':')[1].strip()\n",
    "        \n",
    "    elif \"thehindubusinessline.com\" in pg:\n",
    "        publishbox=soup.find('none')\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'class':'tag-button'})\n",
    "        if tags is not None:\n",
    "            cls=tags.text.strip()\n",
    "        \n",
    "    elif \"business-standard.com\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'itemprop':'datePublished'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'class':'related-keyword'})\n",
    "        if tags is not None:\n",
    "            cls=tags.text.split('|')[-1].strip()\n",
    "        \n",
    "    elif \"catchnews.com\" in pg:\n",
    "        publishbox=soup.findAll('span',attrs={'class':'artical_news_time'})\n",
    "        if publishbox is not None:\n",
    "            for publish in publishbox:\n",
    "                date=datefinder.find_dates(publish.text.strip())\n",
    "                for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'class':'ins_keyword'})\n",
    "        if tags is not None:\n",
    "            cls=tags.text.strip().split('\\n')[0]\n",
    "        \n",
    "    elif \"constructionworld.in\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'class':'date'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'tags'})\n",
    "        if tags is not None:\n",
    "            for link in tags:\n",
    "                a=link.find('a')\n",
    "            a=a.text.strip()\n",
    "    \n",
    "    elif \"daijiworld.com\" in pg:\n",
    "        publishbox=soup.find('ul',attrs={'class':'post-tags'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        \n",
    "    elif \"daily.bhaskar.com\" in pg:\n",
    "        publishbox=soup.find('p',attrs={'class':'dba_pdate'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "    \n",
    "    elif \"bhaskar.com\" in pg:\n",
    "        publishbox=soup.find('p',attrs={'class':'ba_date'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content').split(',')[0]\n",
    "        \n",
    "    elif \"deccanherald.com\" in pg:\n",
    "        publishbox=soup.find('div',attrs={'class':'postedBy'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'class':'breadcrumb'})\n",
    "        if tags is not None:\n",
    "            cls=tags.text.strip().split('»')[1].strip()\n",
    "    \n",
    "    elif \"dnaindia.com\" in pg:\n",
    "        publishbox=soup.find('date')\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "            \n",
    "        tags=soup.find('ol',attrs={'class':'breadcrumbx'})\n",
    "        if tags is not None:\n",
    "            cls=tags.text.strip().split('\\n')[1].strip()\n",
    "        \n",
    "    elif \"equitymaster\" in pg:\n",
    "        publishbox=soup.find('div',attrs={'class':'closeDate'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "    \n",
    "    elif \"cricinfo.com\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'data-dateformat':'date1'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        cls=\"sports\"\n",
    "    \n",
    "    elif \"daily-express-weird\" in pg:\n",
    "        publishbox=soup.find('div',attrs={'class':'dates'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        cls=\"weird\"\n",
    "        \n",
    "    elif \"firstpost.com\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'class':'article-date'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "            \n",
    "        tags=soup.find('a',attrs={'class':'section-btn'})\n",
    "        if tags is not None:\n",
    "            cls=tags.text.strip()\n",
    "        \n",
    "    elif \"fonearena\" in pg:\n",
    "        publishbox=soup.find('time',attrs={'class':'entry-date published updated'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "    \n",
    "        tags=soup.find('meta',attrs={'name':'keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content').split(' ')[0]\n",
    "        \n",
    "    elif \"forbesindia.com\" in pg:\n",
    "        publishbox=soup.find('div',attrs={'class':'update-date'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "    elif \"glamsham.com\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'name':'Last-Modified'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'news_keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0]\n",
    "        \n",
    "    \n",
    "    elif \"huffingtonpost.in\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'class':'timestamp__date timestamp__date--published'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('span',attrs={'class':'entry-eyebrow'})\n",
    "        if tags is not None:\n",
    "            cls=tags.text.strip()\n",
    "    \n",
    "    elif \"indiaglitz\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'itemprop':'datePublished'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'itemprop':'articleSection'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0]\n",
    "    \n",
    "    elif \"indiainfoline\" in pg:\n",
    "        publishbox=soup.find('p',attrs={'class':'source fs14e mt5 mb5'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "    \n",
    "        tags=soup.find('meta',attrs={'name':'keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0]\n",
    "\n",
    "    elif \"indiatoday\"  in pg:\n",
    "        publishbox=soup.find('li',attrs={'class':'pubdata'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'news_keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0]\n",
    "            \n",
    "            \n",
    "    elif \"indiatvnews\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'http-equiv':'Last-Modified'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'news_keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0].split(' ')[0]\n",
    "    \n",
    "    elif \"itnewsonline\" in pg:\n",
    "        datetime=\"\"\n",
    "        cls='technology'\n",
    "    \n",
    "    elif \"kanglaonline\" in pg:\n",
    "        publishbox=soup.find('time',attrs={'class':'entry-date updated td-module-date'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('ul',attrs={'class':'td-tags td-post-small-box clearfix'})\n",
    "        if tags is not None:\n",
    "            a=tags.find('a')\n",
    "            cls=a.text.strip()\n",
    "            \n",
    "    elif \"feedproxy.google.com/~r/LinuxForYou/\" in pg:\n",
    "        publishbox=soup.find('time',attrs={'class':'entry-date'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'class':'meta-tags clearfix'})\n",
    "        if tags is not None:\n",
    "            a=tags.find('a')\n",
    "            cls=a.text.strip()\n",
    "        \n",
    "    elif \"mainstreamweekly\" in pg:\n",
    "        publishbox=soup.find('p',attrs={'class':'surtitre'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "    \n",
    "    elif \"http://feedproxy.google.com/~r/MathrubhumiEnglish/\" in pg:\n",
    "        publishbox=soup.find('div',attrs={'class':'date_outer'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0]\n",
    "    \n",
    "    elif \"http://feedproxy.google.com/~r/allhealthnews/\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'name':'DC.date.issued'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0]\n",
    "    \n",
    "    elif \"http://feedproxy.google.com/~r/medianama/\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'property':'article:published_time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'news_keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0]\n",
    "            \n",
    "    elif \"moneycontrol\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'http-equiv':'Last-Modified'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'news_keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0]\n",
    "            \n",
    "            \n",
    "    elif \"businesstoday\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'itemprop':'datePublished'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content',None).split(',')[0]\n",
    "            \n",
    "    elif \"msn.com\" in pg:       \n",
    "        publishbox=soup.find('span',attrs={'class':'time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        cls=pg.split('/')[5]\n",
    "    \n",
    "    elif \"http://feedproxy.google.com/~r/feedburner/HlRy/\"  in pg:\n",
    "        publishbox=soup.find('span',attrs={'class':'source'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "           \n",
    "    elif \"newsonair.nic.in\" in pg:\n",
    "        publishbox=pg.split('=')[1].split('&')[0].strip()\n",
    "        if publishbox is not None:\n",
    "            cls=publishbox\n",
    "            \n",
    "    elif \"http://feedproxy.google.com/~r/newscomauwtfndm/\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'property':'article:published_time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content').split(',')[0].strip()\n",
    "          \n",
    "    elif \"nowrunning.com\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'name':'pubdate'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=pg.split('/')[5]\n",
    "        if tags is not None:\n",
    "            cls=tags.strip()\n",
    "          \n",
    "    elif \"odditycentral.com\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'property':'article:published_time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('span',attrs={'class':'post-info'})\n",
    "        if tags is not None:\n",
    "            a=tags.find('a')\n",
    "            cls=a.text.strip()\n",
    "   \n",
    "    elif \"feedproxy.google.com/~r/oneindia\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'property':'article:published_time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=pg.split('/')[4].split('-')[-1]\n",
    "        if tags is not None:\n",
    "            cls=tags.strip()\n",
    "    \n",
    "    elif \"feedproxy.google.com/~r/openthemagazine/\" in pg:\n",
    "        publishbox=soup.find('time',attrs={'class':'pub_date'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content').split(',')[0].strip()\n",
    "    \n",
    "    elif \"pib.nic.in\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'style':'float:right;font-size:80%;font-weight:lighter'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'id':'thd1'})\n",
    "        if tags is not None:\n",
    "            cls='Government of India'\n",
    "   \n",
    "    elif \"feedproxy.google.com/~r/pluggd/\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'property':'article:published_time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "            \n",
    "    elif \"prokerala.com\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'itemprop':'datePublished'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "    \n",
    "    elif \"www.rediff.com\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'itemprop':'datePublished'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=pg.split('/')[3].strip()\n",
    "        if tags is not None:\n",
    "            cls=tags\n",
    "    \n",
    "    elif \"http://feeds.reuters.com/~r/reuters/\" in pg:\n",
    "        publishbox=soup.find('div',attrs={'class':'date_V9eGk'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('div',attrs={'class':'channel_4KD-f'})\n",
    "        if tags is not None:\n",
    "            a=tags.find('a')\n",
    "            cls=a.text.strip()\n",
    "    \n",
    "    elif \"saharasamay\" in pg:\n",
    "        publishbox=soup.find('td',attrs={'id':'printDate'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'Keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content').split(',')[0]\n",
    "    \n",
    "    elif \"www.santabanta.com\" in pg:\n",
    "        publishbox=soup.find('div',attrs={'id':'pubdate'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=pg.split('/')[3]\n",
    "        if tags is not None:\n",
    "            cls=tags.strip()\n",
    "            \n",
    "    elif \"www.sify.com\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'name':'modified-date'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'Keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content').split(',')[0].split(' ')[0].strip()\n",
    "            \n",
    "    elif \"sikhsiyasat.net\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'property':'article:published_time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'property':'article:section'})\n",
    "        if tags is not None:\n",
    "            cls='politics'\n",
    "    \n",
    "    elif \"www.sportskeeda.com\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'class':'keeda-time-since'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "            print(datetime)\n",
    "        cls='sports'\n",
    "    \n",
    "    elif \"tech.firstpost.com\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'property':'og:updated_time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        cls='technology'\n",
    "        \n",
    "    elif \"www.mydigitalfc.com\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'datatype':'xsd:dateTime'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        cls='finance'\n",
    "    \n",
    "    elif \"www.telegraph.co.uk\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'name':'DCSext.articleFirstPublished'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'name':'keywords'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content').split(',')[0].strip()\n",
    "    \n",
    "    elif \"www.topnews.in\" in pg:\n",
    "        publishbox=soup.find('span',attrs={'class':'submitted'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('span',attrs={'class':'taxonomy'})\n",
    "        if tags is not None:\n",
    "            a=tags.find('a')\n",
    "            cls=a.text.strip().split(' ')[0]\n",
    "            \n",
    "    elif \"trak.in\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'property':'article:published_time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'property':'article:section'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content').strip()\n",
    "\n",
    "    elif \"valueresearchonline.com\" in pg:\n",
    "        publishbox=soup.find('p',attrs={'class':'dateline'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.text.strip())\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "            print(datetime)\n",
    "    \n",
    "    elif \"zeenews.india.com\" in pg:\n",
    "        publishbox=soup.find('meta',attrs={'property':'og:updated_time'})\n",
    "        if publishbox is not None:\n",
    "            date=datefinder.find_dates(publishbox.get('content',None))\n",
    "            for i in date:\n",
    "                datetime='{:%Y-%m-%d}'.format(i)\n",
    "        tags=soup.find('meta',attrs={'property':'article:tag'})\n",
    "        if tags is not None:\n",
    "            cls=tags.get('content').strip()\n",
    "    \n",
    "    tupl=(pg,datetime,cls)        \n",
    "    sheet.append(tupl)\n",
    "    book.save(r'C:\\Users\\windows\\Desktop\\Bigdata dataset\\book1.xlsx')\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/download.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
